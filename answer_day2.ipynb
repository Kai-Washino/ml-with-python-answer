{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24636b4",
   "metadata": {},
   "source": [
    "# 復習問題\n",
    "\n",
    "整数のリストから条件を満たす要素だけを選択し，その合計を計算する関数を書いてください．\n",
    "\n",
    "#### 具体例  \n",
    "あるlist numbersと変数 thressholdがあります．  \n",
    "そのnumbersは0から25までの5の倍数の数字です．  \n",
    "thresholdが12の場合は15と20と25が足されて，60が戻り値です．  \n",
    "\n",
    "ただしfor文とif文は使いましょう．  \n",
    "出来る人はnumbersを作成する際に，リスト内包表記を使ってみましょう．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9295da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 10, 15, 20, 25]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "def sum_over_threshold(numbers, threshold):\n",
    "    val = 0\n",
    "    for number in numbers:\n",
    "        if number > thresholod:\n",
    "            val += number\n",
    "    return val\n",
    "\n",
    "numbers = [x * 5 for x in range(6)]\n",
    "print(numbers)\n",
    "threshold = 12\n",
    "print(sum_over_threshold(numbers, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec6dc2",
   "metadata": {},
   "source": [
    "## 問題1\n",
    "アヤメのデータセットを用いて機械学習モデルを訓練する際，データセットを訓練セットとテストセットに分割する理由はなぜですか？\n",
    "\n",
    "A. モデルが訓練データに過剰適合（過学習）するのを防ぐため  \n",
    "B. 訓練プロセスを高速化するため  \n",
    "C. モデルのパフォーマンスを実際の未知のデータで評価するため  \n",
    "D. データセットのサイズを小さくするため  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6fe6e",
   "metadata": {},
   "source": [
    "## 答え1\n",
    "C\n",
    "\n",
    "##### Aについて\n",
    "過学習はモデルが訓練データに過剰に適合して，新しいデータに対する汎化性能が低いこと  \n",
    "\n",
    "過学習を防ぐには，\n",
    "- 訓練データの量を増やすこと  \n",
    "- 関係がない特徴量を除外すること  \n",
    "- 単純なモデルを使用する  \n",
    "- 正規化を使う（2章）  \n",
    "- クロスバリデーションの使用  \n",
    "- 早期に停止する  \n",
    "\n",
    "##### Bについて\n",
    "訓練プロセスを高速化するためには，\n",
    "- データサイズの削減\n",
    "- 特徴量を選択する\n",
    "- モデルを単純化\n",
    "- バッチ処理（ディープラーニングで使われる）\n",
    "- 並列処理\n",
    "- アルゴリズムの選択\n",
    "- 早期停止"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590f25f",
   "metadata": {},
   "source": [
    "## 問題2\n",
    "アヤメのデータセットには，がくの長さと幅、花びらの長さと幅の4つの特徴量が含まれています。モデルの性能を向上させるために特徴量を選択する際の考慮点は何ですか？\n",
    "\n",
    "A. すべての特徴量を使用すれば、モデルの性能が最も良くなる  \n",
    "B. 相関関係が高い特徴量のみを選択する  \n",
    "C. 特徴量間の相関関係と、特徴量が目的変数とどのように関連しているかを考慮する  \n",
    "D. 最も分散が大きい特徴量を選択する  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b947135e",
   "metadata": {},
   "source": [
    "## 答え2\n",
    "C\n",
    "\n",
    "##### Cについて  \n",
    "特徴量が強く相関している場合，一方の特徴量がもう一方の情報を部分的にまたは完全に含んでいる．  \n",
    "このような場合，過学習が起きやすくなる．  \n",
    "例えば，アヤメのがくの長さとがくの幅が強く相関している場合，両方をモデルに含める必要はない  \n",
    "\n",
    "目的変数とは，アヤメの種類のこと  \n",
    "各特徴量が目的変数の予測にどれだけ貢献しているかを評価する．  \n",
    "相関係数や順位相関などを用いて，定量的に評価する  \n",
    "\n",
    "##### Aについて\n",
    "特徴量が多い場合以下の問題が起こる可能性がある．  \n",
    "- 過学習が起きやすくなる\n",
    "- 必要なデータ量が指数関数的に増加する\n",
    "- 計算コストが増加する\n",
    "\n",
    "\n",
    "##### Bについて\n",
    "相関係数が高い特徴量**のみ**選択すると起きる問題\n",
    "- 相関係数が高い特徴量のみを使用する場合，互いに情報を重複しもっている（多重共線性）ため，モデルの性能向上に寄与しないことがある\n",
    "- 相関が低い特徴量が重要な情報をもっている可能性があり，全体的なパタンを捉えられないことがある\n",
    "\n",
    "##### Dについて\n",
    "分散が大きい特徴量を選択することについて\n",
    "- そもそもあまり関係がない\n",
    "- 偏った特定の特徴量に依存し，モデルがノイズに過剰適応する原因となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b9077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sepal_length = np.array([5.9, 5.8, 6.8, 4.7, 6.9, 5.0, 5.4, 5.0, 6.5, 6.7, 6.0, 6.7, 5.6, 7.7, 6.3, 5.5, 6.3, 6.3, 4.9, 6.3, 7.0, 6.5, 6.0, 4.8, 5.8, 5.6, 5.6, 5.5, 6.1, 7.2, 5.3, 4.3, 6.4, 5.7, 5.4, 5.7, 6.9, 4.6, 5.9, 5.1, 4.6, 6.2, 7.2, 5.7, 4.8, 7.1, 6.9, 6.5, 6.4, 5.1, 4.8, 6.5, 6.7, 4.5, 6.2, 4.9, 5.7, 6.9, 4.4, 5.0, 7.2, 5.1, 4.4, 5.4, 5.5, 6.8, 7.6, 5.1, 4.9, 5.2, 5.7, 6.6, 5.0, 5.1, 6.4, 5.4, 7.7, 4.9, 7.9, 6.7, 5.2, 6.0, 5.8, 7.7, 5.1, 4.7, 7.4, 5.0, 6.3, 5.7, 5.8, 5.7, 6.4, 6.7, 6.3, 6.7, 5.0, 5.5, 6.7, 5.8, 5.1, 6.6, 5.6, 5.9, 6.3, 5.5, 5.1, 4.9, 6.3, 5.8, 7.7, 4.6])\n",
    "petal_length = np.array([4.2, 4.0, 5.5, 1.3, 5.1, 1.6, 1.5, 3.5, 5.5, 5.7, 5.0, 5.8, 3.9, 6.1, 4.7, 3.8, 4.9, 5.1, 4.5, 5.0, 4.7, 5.2, 4.5, 1.6, 5.1, 4.2, 3.6, 4.0, 4.6, 6.0, 1.5, 1.1, 5.3, 4.2, 1.7, 1.5, 4.9, 1.5, 5.1, 3.0, 1.4, 4.5, 6.1, 4.2, 1.4, 5.9, 5.7, 5.8, 5.6, 1.6, 1.6, 5.1, 5.7, 1.3, 5.4, 1.4, 5.0, 5.4, 1.3, 1.4, 5.8, 1.4, 1.3, 1.7, 4.0, 5.9, 6.6, 1.4, 1.5, 1.4, 4.5, 4.4, 1.2, 1.7, 4.3, 1.5, 6.9, 3.3, 6.4, 4.4, 1.5, 4.8, 1.2, 6.7, 1.5, 1.6, 6.1, 1.4, 5.6, 4.1, 3.9, 3.5, 5.3, 5.2, 4.9, 5.0, 1.6, 3.7, 5.6, 5.1, 1.5, 4.6, 4.1, 4.8, 4.4, 1.3, 1.5, 1.5, 5.6, 4.1, 6.7, 1.4])\n",
    "label = np.array([1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2, 0])\n",
    "\n",
    "iris_dataset = np.column_stack((sepal_length, petal_length))\n",
    "print(iris_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd71b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset, label, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26075836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97beeecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ceac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S2\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\S2\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923ccd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
